seml:
  executable: main_seml.py
  name: paper
  output_dir: gitignored/logs
  project_root_dir: .
  conda_environment: gr

slurm:
  experiments_per_job: 1
  sbatch_options:
    gres: gpu:1       # num GPUs
    mem: 64G          # memory
    exclude: gpu[18-19]
    cpus-per-task: 1  # num cores
    time: 0-16:00     # max time, D-HH:MM
    partition: ['gpu_all']
#    qos: students

###### BEGIN PARAMETER CONFIGURATION ######

fixed:
  arguments:
    eval_freq: 1000  # evaluate every n batches
    save_freq: 1e6  # save model every n epochs, besides before and after training
    batch_size: 256 # 128  # size of batches, for Imagenette 128
#    seed: 1234  # random seed
    max_training_minutes: 6120  # one hour and a 45 minutes max, process killed after n minutes (after finish of epoch)
    plot_weights_freq: 50  # plot pictures to tensorboard every n epochs
    prune_freq: 40  # if pruning during training: how long to wait between pruning events after first pruning
    prune_delay: 69  # "if pruning during training: how long to wait before pruning first time
    lower_limit: 0.5
    epochs: 80
    rewind_to: 10  # rewind to this epoch if rewinding is done
    hidden_dim: None
    input_dim: None
    output_dim: None
    N: 1  # size of dataset (used for l0)
    snip_steps: 5  # 's' in algorithm box, number of pruning steps for 'rule of thumb', TODO
    pruning_rate: 0.00  # pruning rate passed to criterion at pruning event. however, most override this
    growing_rate: 0.0000  # grow back so much every epoch (for future criterions)
#    pruning_limit: 0.5  # Prune until here, if structured in nodes, if unstructured in weights. most criterions use this instead of the pruning_rate
    prune_to: 40
    learning_rate: 2e-3
    grad_clip: 10
    grad_noise: 0  # added gaussian noise to gradients
    l2_reg: 5e-5  # weight decay
    l1_reg: 0  # l1-norm regularisation
    lp_reg: 0  # lp regularisation with p < 1
    l0_reg: 1.0  # l0 reg lambda hyperparam
    hoyer_reg: 1.0  # hoyer reg lambda hyperparam
    beta_ema: 0.999  # l0 reg beta ema hyperparam
    structured_prior: 0

    loss: CrossEntropy
    optimizer: ADAM
    model: VGG16 # WideResNet28x10  # ResNet not supported with structured
    data_set: CIFAR10
#    prune_criterion: SNIP  # HoyerSquare is one shot, pruning limit doesn't matter in this implementation
    train_scheme: DefaultTrainer  # default: DefaultTrainer

    device: cuda
    pruning_device: cuda

    checkpoint_name: None
    checkpoint_model: None

    disable_cuda_benchmark: 1  # speedup (disable) vs reproducibility (leave it)
    eval: 0
    disable_autoconfig: 0  # for the brave
    preload_all_data: 0  # load all data into ram memory for speedups
    tuning: 0  # splits trainset into train and validationset, omits test set

    track_weights: 0  # "keep statistics on the weights through training
    disable_masking: 1  # disable the ability to prune unstructured
    enable_rewinding: 0  # enable the ability to rewind to previous weights
    outer_layer_pruning: 1  # allow to prune outer layers (unstructured) or not (structured)
    random_shuffle_labels: 0  # run with random-label experiment from zhang et al
    l0: 0  # run with l0 criterion, might overwrite some other arguments
    hoyer_square: 0  # "run in unstructured DeephoyerSquare criterion, might overwrite some other arguments
    group_hoyer_square: 0 # run in unstructured Group-DeephoyerSquare criterion, might overwrite some other arguments

    disable_histograms: 0
    disable_saliency: 0
    disable_confusion: 0
    disable_weightplot: 0
    disable_netplot: 0
    skip_first_plot: 0

#hoyer_square:
#  fixed:
#    arguments:
#      loss: "HoyerSquare"
#      prune_criterion: "HoyerSquare"

#MNIST:
#  fixed:
#    arguments:
#      input_dim: [1, 28, 28]
#      output_dim: 10
#      hidden_dim: [512]
#      N: 60000
#
CIFAR10:
  fixed:
    arguments:
      input_dim: [3, 32, 32]
      output_dim: 10
      hidden_dim: [512]
      N: 60000
#CIFAR100:
#  fixed:
#    arguments:
#      input_dim: [ 3, 32, 32 ]
#      output_dim: 100
#      hidden_dim: [512]
#      N: 60000

#TINYIMAGENET:
#  fixed:
#    arguments:
#      input_dim: [3, 128, 128]
#      output_dim: 20000
#      hidden_dim: [512]
#      N: 100096

grid:
  arguments:
    seed:
      type: choice
      options:
        - 1234
#        - 2345
#        - 3456
#        - 4567
#        - 5678

    prune_criterion:
      type: choice
      options:
#        - StructuredRandom
#        - StructuredEFGitDuring
#        - EarlyStructuredEFGit
#                - SNAP
#        - SNAP_tbd
#        - EfficientConvNets
#        - GateDecorators
#        - StructuredEFG
#        - StructuredEFGit
    #        - HoyerSquare
#        - EmptyCrit
#        - EarlyBird
#        - UnstructuredRandom
#        - SNIP
#        - GRASP
#        - John
#        - Johnit
        - EarlyJohn
#        - IMP

#    prune_to:
#      type: range
#      min: 0
#      max: 40
#      step: 1

    pruning_limit:
      type: choice
      options:
        - 0.5
        - 0.6
        - 0.7
        - 0.8
        - 0.85
        - 0.86
        - 0.87
        - 0.88
        - 0.89
        - 0.9
        - 0.91
        - 0.92
        - 0.93
        - 0.94
        - 0.95
        - 0.96
        - 0.97
        - 0.98
        - 0.99
        - 0.995

#    hoyer_reg:
#      type: loguniform
#      min: 1e-5
#      max: 5
#      num: 10

#    train_scheme:
#      type: choice
#      options:
#        - DefaultTrainer
#        - AdversarialTrainer

#    seed:
#      type: choice
#      options:
#        - 111
#        - 222
#        - 333
#

#    prune_criterion:
#      type: choice
#      options:
#        - SNIP
#        - GRASP
#        - SNIPit

# l0:
#   fixed:
#     arguments:
#       loss: "L0CrossEntropy"
#       train_scheme: "L0Trainer"
#       prune_criterion: "EmptyCrit"
#       pruning_rate: 0.0
#       growing_rate: 0.0
#       outer_layer_pruning: True
#       disable_weightplot: False
#       disable_netplot: False
#       prune_delay: 10000000000000

# group_hoyer_square:
#   fixed:
#     arguments:
#       loss: "GroupHoyerSquare"
#       prune_criterion: "GroupHoyerSquare"

# FASHION:
#   fixed:
#     arguments:
#       input_dim: [1, 28, 28]
#       output_dim: 10
#       hidden_dim: [512]
#       N: 60000

# OMNIGLOT:
#   fixed:
#     arguments:
#       input_dim: [
#                 1,
#                 105,
#                 105
#         ]
#       output_dim: 1623
#       hidden_dim: [
#                 512
#         ]
#       N: 19456

# "CIFAR10": {
#         "input_dim": [
#                 3,
#                 32,
#                 32
#         ],
#         "output_dim": 10,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 50000
# },
# "CIFAR100": {
#         "input_dim": [
#                 3,
#                 32,
#                 32
#         ],
#         "output_dim": 100,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 50000
# },


# "TEST@HOME": {
#         "input_dim": [
#                 3,
#                 244,
#                 244
#         ],
#         "output_dim": 2,
#         "hidden_dim": [
#                 128
#         ],
#         "N": -1
# },
# "RUBBISH": {
#         "input_dim": [
#                 1,
#                 3,
#                 3
#         ],
#         "output_dim": 2,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 10000
# },
# "TINYIMAGENET": {
#         "input_dim": [
#                 3,
#                 128,
#                 128
#         ],
#         "output_dim": 20000,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 100096
# },
# "IMAGENETTE": {
#         "input_dim": [
#                 3,
#                 128,
#                 128
#         ],
#         "output_dim": 10,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 12928
# },
# "IMAGEWOOF": {
#         "input_dim": [
#                 3,
#                 128,
#                 128
#         ],
#         "output_dim": 10,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 12928