#!/bin/bash
#SBATCH -N 1 # number of nodes
#SBATCH --gres=gpu:1 # number of GPUs to be allocated
#SBATCH --partition gpu_all #gpu_all #gpu_all  # cpu
#SBATCH -t 0-24:00 # time after which the process will be killed (D-HH:MM)
#SBATCH -o "/nfs/homedirs/%u/slurm-output/slurm-%j.out"
#SBATCH --mem=128000 # the memory (MB) that is allocated to the job. If your job exceeds this it will be killed but don't set it too large since it will block resources and will lead to your job being given a low priority by the scheduler.
#SBATCH --qos=interactive   # this qos ensures a very high priority but only one job per user can run under this mode.
#SBATCH --cpus-per-task=1

cd ${SLURM_SUBMIT_DIR}
echo Starting job ${SLURM_JOBID}
echo SLURM assigned me these nodes:
squeue -j ${SLURM_JOBID} -O nodelist | tail -n +2

# Activate your conda environment if necessary
source ~/miniconda3/etc/profile.d/conda.sh
conda activate gr

export XDG_RUNTIME_DIR="" # Fixes Jupyter bug with read/write permissions https://github.com/jupyter/notebook/issues/1318
jupyter notebook --no-browser --ip=$(hostname).kdd.in.tum.de
#tensorboard --logdir ./gitignored/results/
#python main.py --model VGG16 --data_set TINYIMAGENET --outer_layer_pruning --prune_criterion EmptyCrit --batch_size 128 --epochs 80
#python main.py --model ResNext --train_scheme ResnextTrainer --data_set CIFAR10 --prune_criterion EmptyCrit --pruning_limit 0.65 --epochs 80 --batch_size 64